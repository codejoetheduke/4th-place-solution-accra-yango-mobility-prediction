{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T16:04:07.189677Z",
     "iopub.status.busy": "2024-11-25T16:04:07.189333Z",
     "iopub.status.idle": "2024-11-25T16:04:07.209724Z",
     "shell.execute_reply": "2024-11-25T16:04:07.208736Z",
     "shell.execute_reply.started": "2024-11-25T16:04:07.189643Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np # linear algebra\n",
    "random.seed(42) #For Reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Included matplotlib.pyplot and seaborn for visualization. However in this notebook, i only did feature extraction, preprocessing and modeling of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-25T16:04:07.229412Z",
     "iopub.status.busy": "2024-11-25T16:04:07.228983Z",
     "iopub.status.idle": "2024-11-25T16:04:11.005795Z",
     "shell.execute_reply": "2024-11-25T16:04:11.004871Z",
     "shell.execute_reply.started": "2024-11-25T16:04:07.229371Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# import matplotlib.pyplot as plt # data visualization\n",
    "# import seaborn as sns # statistical data visualization\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import os\n",
    "import statistics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Imports and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this import path is for my folder setup. Please change path to where your Train, Test and Graph datasets are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T16:04:11.008834Z",
     "iopub.status.busy": "2024-11-25T16:04:11.008049Z",
     "iopub.status.idle": "2024-11-25T16:04:12.320766Z",
     "shell.execute_reply": "2024-11-25T16:04:12.319866Z",
     "shell.execute_reply.started": "2024-11-25T16:04:11.008779Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>persistent_id</th>\n",
       "      <th>day</th>\n",
       "      <th>prediction_type</th>\n",
       "      <th>count_norm_00_0_</th>\n",
       "      <th>count_norm_00_1_</th>\n",
       "      <th>count_norm_00_2_</th>\n",
       "      <th>count_norm_00_3_</th>\n",
       "      <th>count_norm_01_0_</th>\n",
       "      <th>count_norm_01_1_</th>\n",
       "      <th>...</th>\n",
       "      <th>speed_avg_21_3_</th>\n",
       "      <th>speed_avg_22_0_</th>\n",
       "      <th>speed_avg_22_1_</th>\n",
       "      <th>speed_avg_22_2_</th>\n",
       "      <th>speed_avg_22_3_</th>\n",
       "      <th>speed_avg_23_0_</th>\n",
       "      <th>speed_avg_23_1_</th>\n",
       "      <th>speed_avg_23_2_</th>\n",
       "      <th>speed_avg_23_3_</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5265971867368357888_X_lbo_weekday_X_morning_ru...</td>\n",
       "      <td>5265971867368357888</td>\n",
       "      <td>lbo_weekday</td>\n",
       "      <td>morning_rush_hour</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.214111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17637398975726110720_X_other_holiday_X_morning...</td>\n",
       "      <td>17637398975726110720</td>\n",
       "      <td>other_holiday</td>\n",
       "      <td>morning_rush_hour</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.486919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8568741015432481792_X_other_weekday_X_evening_...</td>\n",
       "      <td>8568741015432481792</td>\n",
       "      <td>other_weekday</td>\n",
       "      <td>evening_rush_hour</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>13.457778</td>\n",
       "      <td>11.028648</td>\n",
       "      <td>11.424647</td>\n",
       "      <td>14.729181</td>\n",
       "      <td>13.025704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.772556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464534661918074112_X_first_holiday_X_evening_...</td>\n",
       "      <td>1464534661918074112</td>\n",
       "      <td>first_holiday</td>\n",
       "      <td>evening_rush_hour</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15.166433</td>\n",
       "      <td>13.408104</td>\n",
       "      <td>15.358508</td>\n",
       "      <td>16.056136</td>\n",
       "      <td>16.868352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.378477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4278874665015895552_X_last_weekday_X_morning_r...</td>\n",
       "      <td>4278874665015895552</td>\n",
       "      <td>last_weekday</td>\n",
       "      <td>morning_rush_hour</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.317734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 165 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ID         persistent_id  \\\n",
       "0  5265971867368357888_X_lbo_weekday_X_morning_ru...   5265971867368357888   \n",
       "1  17637398975726110720_X_other_holiday_X_morning...  17637398975726110720   \n",
       "2  8568741015432481792_X_other_weekday_X_evening_...   8568741015432481792   \n",
       "3  1464534661918074112_X_first_holiday_X_evening_...   1464534661918074112   \n",
       "4  4278874665015895552_X_last_weekday_X_morning_r...   4278874665015895552   \n",
       "\n",
       "             day    prediction_type  count_norm_00_0_  count_norm_00_1_  \\\n",
       "0    lbo_weekday  morning_rush_hour          0.000119          0.000089   \n",
       "1  other_holiday  morning_rush_hour          0.000554          0.000408   \n",
       "2  other_weekday  evening_rush_hour               NaN               NaN   \n",
       "3  first_holiday  evening_rush_hour               NaN               NaN   \n",
       "4   last_weekday  morning_rush_hour          0.000021          0.000020   \n",
       "\n",
       "   count_norm_00_2_  count_norm_00_3_  count_norm_01_0_  count_norm_01_1_  \\\n",
       "0          0.000089          0.000069          0.000029          0.000059   \n",
       "1          0.000417          0.000471          0.000427          0.000435   \n",
       "2               NaN               NaN               NaN               NaN   \n",
       "3               NaN               NaN               NaN               NaN   \n",
       "4               NaN          0.000029               NaN          0.000010   \n",
       "\n",
       "   ...  speed_avg_21_3_  speed_avg_22_0_  speed_avg_22_1_  speed_avg_22_2_  \\\n",
       "0  ...              NaN              NaN              NaN              NaN   \n",
       "1  ...              NaN              NaN              NaN              NaN   \n",
       "2  ...        13.457778        11.028648        11.424647        14.729181   \n",
       "3  ...        15.166433        13.408104        15.358508        16.056136   \n",
       "4  ...              NaN              NaN              NaN              NaN   \n",
       "\n",
       "   speed_avg_22_3_  speed_avg_23_0_  speed_avg_23_1_  speed_avg_23_2_  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1              NaN              NaN              NaN              NaN   \n",
       "2        13.025704              NaN              NaN              NaN   \n",
       "3        16.868352              NaN              NaN              NaN   \n",
       "4              NaN              NaN              NaN              NaN   \n",
       "\n",
       "   speed_avg_23_3_     target  \n",
       "0              NaN  11.214111  \n",
       "1              NaN  18.486919  \n",
       "2              NaN   9.772556  \n",
       "3              NaN  14.378477  \n",
       "4              NaN  11.317734  \n",
       "\n",
       "[5 rows x 165 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = '/kaggle/input/yango-accra-mobility-dataset' # change data path to your drive\n",
    "# Load files\n",
    "train = pd.read_csv(os.path.join(DATA_PATH, 'Train.csv'))\n",
    "test = pd.read_csv(os.path.join(DATA_PATH, 'Test.csv'))\n",
    "samplesubmission = pd.read_csv(os.path.join(DATA_PATH, 'SampleSubmission.csv'))\n",
    "graph_df = pd.read_csv(os.path.join(DATA_PATH, 'Graph.csv'))\n",
    "\n",
    "# Preview train dataset\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a function that will be used to Lookup from the graph.csv file that has more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T16:04:12.322061Z",
     "iopub.status.busy": "2024-11-25T16:04:12.321778Z",
     "iopub.status.idle": "2024-11-25T16:04:12.392665Z",
     "shell.execute_reply": "2024-11-25T16:04:12.391576Z",
     "shell.execute_reply.started": "2024-11-25T16:04:12.322036Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30306 entries, 0 to 30305\n",
      "Columns: 171 entries, ID to traffic_side\n",
      "dtypes: float64(167), object(3), uint64(1)\n",
      "memory usage: 39.5+ MB\n"
     ]
    }
   ],
   "source": [
    "def look_up_from_graph(train,graph,lookup_columns):\n",
    "  # returns dataframe by looking up columns from the graph.csv\n",
    "\n",
    "  train = train.copy()\n",
    "  graph = graph.copy()\n",
    "\n",
    "  train = train.merge(graph[lookup_columns], on = \"persistent_id\", how = \"left\")\n",
    "\n",
    "  return train\n",
    "\n",
    "\"\"\"\n",
    "Save columns to lookup from the graph dataset, I found that these did not work well even though they seem very useful -- they lead to overfitting quite easily didn't have time to investigate why this happened.\n",
    "The best model should include at least a subset of these\n",
    "\"\"\"\n",
    "preliminary_columns = [\"persistent_id\",\"length\", \"speed_limit\", \"segments\",\"category\",\"is_residential\", \"traffic_side\"]\n",
    "\n",
    "train = look_up_from_graph(train,graph_df,preliminary_columns)\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T16:04:12.396173Z",
     "iopub.status.busy": "2024-11-25T16:04:12.395665Z",
     "iopub.status.idle": "2024-11-25T16:04:12.419746Z",
     "shell.execute_reply": "2024-11-25T16:04:12.418531Z",
     "shell.execute_reply.started": "2024-11-25T16:04:12.396123Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>persistent_id</th>\n",
       "      <th>day</th>\n",
       "      <th>prediction_type</th>\n",
       "      <th>count_norm_00_0_</th>\n",
       "      <th>count_norm_00_1_</th>\n",
       "      <th>count_norm_00_2_</th>\n",
       "      <th>count_norm_00_3_</th>\n",
       "      <th>count_norm_01_0_</th>\n",
       "      <th>count_norm_01_1_</th>\n",
       "      <th>...</th>\n",
       "      <th>speed_avg_23_1_</th>\n",
       "      <th>speed_avg_23_2_</th>\n",
       "      <th>speed_avg_23_3_</th>\n",
       "      <th>target</th>\n",
       "      <th>length</th>\n",
       "      <th>speed_limit</th>\n",
       "      <th>segments</th>\n",
       "      <th>category</th>\n",
       "      <th>is_residential</th>\n",
       "      <th>traffic_side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5265971867368357888_X_lbo_weekday_X_morning_ru...</td>\n",
       "      <td>5265971867368357888</td>\n",
       "      <td>lbo_weekday</td>\n",
       "      <td>morning_rush_hour</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.214111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17637398975726110720_X_other_holiday_X_morning...</td>\n",
       "      <td>17637398975726110720</td>\n",
       "      <td>other_holiday</td>\n",
       "      <td>morning_rush_hour</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.486919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8568741015432481792_X_other_weekday_X_evening_...</td>\n",
       "      <td>8568741015432481792</td>\n",
       "      <td>other_weekday</td>\n",
       "      <td>evening_rush_hour</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.772556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464534661918074112_X_first_holiday_X_evening_...</td>\n",
       "      <td>1464534661918074112</td>\n",
       "      <td>first_holiday</td>\n",
       "      <td>evening_rush_hour</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.378477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4278874665015895552_X_last_weekday_X_morning_r...</td>\n",
       "      <td>4278874665015895552</td>\n",
       "      <td>last_weekday</td>\n",
       "      <td>morning_rush_hour</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.317734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ID         persistent_id  \\\n",
       "0  5265971867368357888_X_lbo_weekday_X_morning_ru...   5265971867368357888   \n",
       "1  17637398975726110720_X_other_holiday_X_morning...  17637398975726110720   \n",
       "2  8568741015432481792_X_other_weekday_X_evening_...   8568741015432481792   \n",
       "3  1464534661918074112_X_first_holiday_X_evening_...   1464534661918074112   \n",
       "4  4278874665015895552_X_last_weekday_X_morning_r...   4278874665015895552   \n",
       "\n",
       "             day    prediction_type  count_norm_00_0_  count_norm_00_1_  \\\n",
       "0    lbo_weekday  morning_rush_hour          0.000119          0.000089   \n",
       "1  other_holiday  morning_rush_hour          0.000554          0.000408   \n",
       "2  other_weekday  evening_rush_hour               NaN               NaN   \n",
       "3  first_holiday  evening_rush_hour               NaN               NaN   \n",
       "4   last_weekday  morning_rush_hour          0.000021          0.000020   \n",
       "\n",
       "   count_norm_00_2_  count_norm_00_3_  count_norm_01_0_  count_norm_01_1_  \\\n",
       "0          0.000089          0.000069          0.000029          0.000059   \n",
       "1          0.000417          0.000471          0.000427          0.000435   \n",
       "2               NaN               NaN               NaN               NaN   \n",
       "3               NaN               NaN               NaN               NaN   \n",
       "4               NaN          0.000029               NaN          0.000010   \n",
       "\n",
       "   ...  speed_avg_23_1_  speed_avg_23_2_  speed_avg_23_3_     target  length  \\\n",
       "0  ...              NaN              NaN              NaN  11.214111     NaN   \n",
       "1  ...              NaN              NaN              NaN  18.486919     NaN   \n",
       "2  ...              NaN              NaN              NaN   9.772556     NaN   \n",
       "3  ...              NaN              NaN              NaN  14.378477     NaN   \n",
       "4  ...              NaN              NaN              NaN  11.317734     NaN   \n",
       "\n",
       "   speed_limit  segments  category  is_residential  traffic_side  \n",
       "0          NaN       NaN       NaN             NaN           NaN  \n",
       "1          NaN       NaN       NaN             NaN           NaN  \n",
       "2          NaN       NaN       NaN             NaN           NaN  \n",
       "3          NaN       NaN       NaN             NaN           NaN  \n",
       "4          NaN       NaN       NaN             NaN           NaN  \n",
       "\n",
       "[5 rows x 171 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a function that picks all our categorical features, we will need this for LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T16:04:12.421398Z",
     "iopub.status.busy": "2024-11-25T16:04:12.421121Z",
     "iopub.status.idle": "2024-11-25T16:04:12.426633Z",
     "shell.execute_reply": "2024-11-25T16:04:12.425553Z",
     "shell.execute_reply.started": "2024-11-25T16:04:12.421372Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def change_object_to_cat(df):\n",
    "  # changes object columns to category and returns dataframe and list of converted columns\n",
    "\n",
    "  # Make a copy of the DataFrame to avoid modifying the original DataFrame\n",
    "  df = df.copy()\n",
    "\n",
    "  # Identify columns of type \"object\" (typically string columns) in the DataFrame\n",
    "  list_str_obj_cols = df.columns[df.dtypes == \"object\"].tolist()\n",
    "\n",
    "  # Convert each identified object-type column to category\n",
    "  for str_obj_col in list_str_obj_cols:\n",
    "      df[str_obj_col] = df[str_obj_col].astype(\"category\")\n",
    "\n",
    "  # Return the updated DataFrame and the list of columns that were converted to category type\n",
    "  return df, list_str_obj_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T16:04:12.428940Z",
     "iopub.status.busy": "2024-11-25T16:04:12.428180Z",
     "iopub.status.idle": "2024-11-25T16:04:12.451398Z",
     "shell.execute_reply": "2024-11-25T16:04:12.450346Z",
     "shell.execute_reply.started": "2024-11-25T16:04:12.428886Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get features and target\n",
    "X =  train.drop(['ID', 'persistent_id', 'target'], axis = 1)\n",
    "y = train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T16:04:12.452893Z",
     "iopub.status.busy": "2024-11-25T16:04:12.452581Z",
     "iopub.status.idle": "2024-11-25T16:04:12.473172Z",
     "shell.execute_reply": "2024-11-25T16:04:12.472076Z",
     "shell.execute_reply.started": "2024-11-25T16:04:12.452867Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>prediction_type</th>\n",
       "      <th>count_norm_00_0_</th>\n",
       "      <th>count_norm_00_1_</th>\n",
       "      <th>count_norm_00_2_</th>\n",
       "      <th>count_norm_00_3_</th>\n",
       "      <th>count_norm_01_0_</th>\n",
       "      <th>count_norm_01_1_</th>\n",
       "      <th>count_norm_01_2_</th>\n",
       "      <th>count_norm_01_3_</th>\n",
       "      <th>...</th>\n",
       "      <th>speed_avg_23_0_</th>\n",
       "      <th>speed_avg_23_1_</th>\n",
       "      <th>speed_avg_23_2_</th>\n",
       "      <th>speed_avg_23_3_</th>\n",
       "      <th>length</th>\n",
       "      <th>speed_limit</th>\n",
       "      <th>segments</th>\n",
       "      <th>category</th>\n",
       "      <th>is_residential</th>\n",
       "      <th>traffic_side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lbo_weekday</td>\n",
       "      <td>morning_rush_hour</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>other_holiday</td>\n",
       "      <td>morning_rush_hour</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>other_weekday</td>\n",
       "      <td>evening_rush_hour</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             day    prediction_type  count_norm_00_0_  count_norm_00_1_  \\\n",
       "0    lbo_weekday  morning_rush_hour          0.000119          0.000089   \n",
       "1  other_holiday  morning_rush_hour          0.000554          0.000408   \n",
       "2  other_weekday  evening_rush_hour               NaN               NaN   \n",
       "\n",
       "   count_norm_00_2_  count_norm_00_3_  count_norm_01_0_  count_norm_01_1_  \\\n",
       "0          0.000089          0.000069          0.000029          0.000059   \n",
       "1          0.000417          0.000471          0.000427          0.000435   \n",
       "2               NaN               NaN               NaN               NaN   \n",
       "\n",
       "   count_norm_01_2_  count_norm_01_3_  ...  speed_avg_23_0_  speed_avg_23_1_  \\\n",
       "0          0.000090          0.000030  ...              NaN              NaN   \n",
       "1          0.000281          0.000317  ...              NaN              NaN   \n",
       "2               NaN               NaN  ...              NaN              NaN   \n",
       "\n",
       "   speed_avg_23_2_  speed_avg_23_3_  length  speed_limit  segments  category  \\\n",
       "0              NaN              NaN     NaN          NaN       NaN       NaN   \n",
       "1              NaN              NaN     NaN          NaN       NaN       NaN   \n",
       "2              NaN              NaN     NaN          NaN       NaN       NaN   \n",
       "\n",
       "   is_residential  traffic_side  \n",
       "0             NaN           NaN  \n",
       "1             NaN           NaN  \n",
       "2             NaN           NaN  \n",
       "\n",
       "[3 rows x 168 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview X_train\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T16:04:12.474860Z",
     "iopub.status.busy": "2024-11-25T16:04:12.474568Z",
     "iopub.status.idle": "2024-11-25T16:04:12.548334Z",
     "shell.execute_reply": "2024-11-25T16:04:12.547420Z",
     "shell.execute_reply.started": "2024-11-25T16:04:12.474833Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30306 entries, 0 to 30305\n",
      "Columns: 168 entries, day to traffic_side\n",
      "dtypes: category(2), float64(166)\n",
      "memory usage: 38.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Convert object type columns to categorical and retrieve the list of categorical columns\n",
    "X, cat_list = change_object_to_cat(X)\n",
    "\n",
    "# Print DataFrame information (shows column data types and other details)\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T16:04:12.549691Z",
     "iopub.status.busy": "2024-11-25T16:04:12.549387Z",
     "iopub.status.idle": "2024-11-25T16:04:12.555848Z",
     "shell.execute_reply": "2024-11-25T16:04:12.554683Z",
     "shell.execute_reply.started": "2024-11-25T16:04:12.549665Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['day', 'prediction_type']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training (With LightGBM and CatBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T16:04:12.561427Z",
     "iopub.status.busy": "2024-11-25T16:04:12.560632Z",
     "iopub.status.idle": "2024-11-25T16:04:12.594609Z",
     "shell.execute_reply": "2024-11-25T16:04:12.593776Z",
     "shell.execute_reply.started": "2024-11-25T16:04:12.561385Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# split the dataset into the training set and test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's define a function that trains and returns the model, will be useful for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T16:04:12.596140Z",
     "iopub.status.busy": "2024-11-25T16:04:12.595823Z",
     "iopub.status.idle": "2024-11-25T16:04:12.600864Z",
     "shell.execute_reply": "2024-11-25T16:04:12.599839Z",
     "shell.execute_reply.started": "2024-11-25T16:04:12.596111Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## LightBGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T16:04:12.602837Z",
     "iopub.status.busy": "2024-11-25T16:04:12.602229Z",
     "iopub.status.idle": "2024-11-25T16:04:12.612205Z",
     "shell.execute_reply": "2024-11-25T16:04:12.611163Z",
     "shell.execute_reply.started": "2024-11-25T16:04:12.602664Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def lgbm_trainer(X_train, y_train, X_test, y_test, params, num_round, categorical):\n",
    "    \"\"\"\n",
    "    Trains an LGBM (LightGBM) model using the training data and evaluates it on the validation data.\n",
    "    Returns the trained model (bst).\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare the training dataset for LightGBM\n",
    "    # 'lgb.Dataset' is used to create a LightGBM dataset object from the training data\n",
    "    # 'categorical_feature' specifies which columns are categorical\n",
    "    train_data = lgb.Dataset(X_train, y_train, feature_name=X_train.columns.tolist(), categorical_feature=categorical, free_raw_data=False)\n",
    "\n",
    "    # Prepare the validation dataset for LightGBM in the same way as the training data\n",
    "    validation_data = lgb.Dataset(X_test, y_test, feature_name=X_train.columns.tolist(), categorical_feature=categorical, free_raw_data=False)\n",
    "\n",
    "    # Initialize an empty dictionary to record evaluation results during training\n",
    "    eval_result = {}\n",
    "\n",
    "    # Train the LightGBM model using the specified parameters and datasets\n",
    "    bst = lgb.train(\n",
    "        params,  # Model parameters (e.g., learning rate, number of leaves, etc.)\n",
    "        train_data,  # The training dataset\n",
    "        num_round,  # The number of boosting rounds (iterations)\n",
    "        valid_sets=[train_data, validation_data],  # Datasets to evaluate during training\n",
    "        callbacks=[  # Callbacks to use during training\n",
    "            lgb.early_stopping(stopping_rounds=17),  # Stop training early if the validation score doesn't improve for 17 rounds\n",
    "            lgb.log_evaluation(100),  # Log evaluation results every 100 rounds\n",
    "            lgb.record_evaluation(eval_result)  # Record evaluation results in 'eval_result'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Return the trained model (bst) after training is complete\n",
    "    return bst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T16:04:12.614623Z",
     "iopub.status.busy": "2024-11-25T16:04:12.613737Z",
     "iopub.status.idle": "2024-11-25T16:05:57.543812Z",
     "shell.execute_reply": "2024-11-25T16:05:57.542592Z",
     "shell.execute_reply.started": "2024-11-25T16:04:12.614566Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 17 rounds\n",
      "[100]\ttraining's rmse: 1.37102\tvalid_1's rmse: 1.60122\n",
      "[200]\ttraining's rmse: 1.18768\tvalid_1's rmse: 1.54985\n",
      "[300]\ttraining's rmse: 1.06045\tvalid_1's rmse: 1.52802\n",
      "Early stopping, best iteration is:\n",
      "[302]\ttraining's rmse: 1.05925\tvalid_1's rmse: 1.52777\n",
      "Training until validation scores don't improve for 17 rounds\n",
      "[100]\ttraining's rmse: 1.37023\tvalid_1's rmse: 1.5704\n",
      "[200]\ttraining's rmse: 1.19024\tvalid_1's rmse: 1.52823\n",
      "[300]\ttraining's rmse: 1.06044\tvalid_1's rmse: 1.50647\n",
      "[400]\ttraining's rmse: 0.965589\tvalid_1's rmse: 1.48891\n",
      "Early stopping, best iteration is:\n",
      "[477]\ttraining's rmse: 0.901422\tvalid_1's rmse: 1.47492\n",
      "Training until validation scores don't improve for 17 rounds\n",
      "[100]\ttraining's rmse: 1.36641\tvalid_1's rmse: 1.66811\n",
      "[200]\ttraining's rmse: 1.17929\tvalid_1's rmse: 1.63107\n",
      "[300]\ttraining's rmse: 1.05447\tvalid_1's rmse: 1.60698\n",
      "[400]\ttraining's rmse: 0.959537\tvalid_1's rmse: 1.59688\n",
      "Early stopping, best iteration is:\n",
      "[386]\ttraining's rmse: 0.971855\tvalid_1's rmse: 1.59627\n",
      "Training until validation scores don't improve for 17 rounds\n",
      "[100]\ttraining's rmse: 1.36687\tvalid_1's rmse: 1.60371\n",
      "[200]\ttraining's rmse: 1.18277\tvalid_1's rmse: 1.57366\n",
      "[300]\ttraining's rmse: 1.05704\tvalid_1's rmse: 1.55661\n",
      "Early stopping, best iteration is:\n",
      "[292]\ttraining's rmse: 1.06551\tvalid_1's rmse: 1.55436\n",
      "Training until validation scores don't improve for 17 rounds\n",
      "[100]\ttraining's rmse: 1.3681\tvalid_1's rmse: 1.58585\n",
      "[200]\ttraining's rmse: 1.18294\tvalid_1's rmse: 1.54649\n",
      "Early stopping, best iteration is:\n",
      "[204]\ttraining's rmse: 1.17689\tvalid_1's rmse: 1.54536\n",
      "Training until validation scores don't improve for 17 rounds\n",
      "[100]\ttraining's rmse: 1.36737\tvalid_1's rmse: 1.60612\n",
      "[200]\ttraining's rmse: 1.18823\tvalid_1's rmse: 1.57985\n",
      "Early stopping, best iteration is:\n",
      "[251]\ttraining's rmse: 1.12074\tvalid_1's rmse: 1.56915\n",
      "Training until validation scores don't improve for 17 rounds\n",
      "[100]\ttraining's rmse: 1.37359\tvalid_1's rmse: 1.56437\n",
      "[200]\ttraining's rmse: 1.18804\tvalid_1's rmse: 1.53413\n",
      "[300]\ttraining's rmse: 1.06508\tvalid_1's rmse: 1.51416\n",
      "Early stopping, best iteration is:\n",
      "[298]\ttraining's rmse: 1.0673\tvalid_1's rmse: 1.51398\n",
      "Training until validation scores don't improve for 17 rounds\n",
      "[100]\ttraining's rmse: 1.37116\tvalid_1's rmse: 1.51989\n",
      "[200]\ttraining's rmse: 1.19251\tvalid_1's rmse: 1.47366\n",
      "[300]\ttraining's rmse: 1.06775\tvalid_1's rmse: 1.44892\n",
      "Early stopping, best iteration is:\n",
      "[302]\ttraining's rmse: 1.0645\tvalid_1's rmse: 1.44788\n",
      "Training until validation scores don't improve for 17 rounds\n",
      "[100]\ttraining's rmse: 1.35436\tvalid_1's rmse: 1.83688\n",
      "[200]\ttraining's rmse: 1.17152\tvalid_1's rmse: 1.80392\n",
      "[300]\ttraining's rmse: 1.04286\tvalid_1's rmse: 1.79276\n",
      "Early stopping, best iteration is:\n",
      "[333]\ttraining's rmse: 1.01063\tvalid_1's rmse: 1.78424\n",
      "Training until validation scores don't improve for 17 rounds\n",
      "[100]\ttraining's rmse: 1.36514\tvalid_1's rmse: 1.65861\n",
      "[200]\ttraining's rmse: 1.17878\tvalid_1's rmse: 1.61169\n",
      "[300]\ttraining's rmse: 1.05083\tvalid_1's rmse: 1.58462\n",
      "Early stopping, best iteration is:\n",
      "[308]\ttraining's rmse: 1.04141\tvalid_1's rmse: 1.5839\n",
      "Training until validation scores don't improve for 17 rounds\n",
      "[100]\ttraining's rmse: 1.3513\tvalid_1's rmse: 1.84563\n",
      "[200]\ttraining's rmse: 1.16776\tvalid_1's rmse: 1.81741\n",
      "[300]\ttraining's rmse: 1.03532\tvalid_1's rmse: 1.80466\n",
      "Early stopping, best iteration is:\n",
      "[354]\ttraining's rmse: 0.977026\tvalid_1's rmse: 1.79878\n",
      "Training until validation scores don't improve for 17 rounds\n",
      "[100]\ttraining's rmse: 1.36406\tvalid_1's rmse: 1.64376\n",
      "[200]\ttraining's rmse: 1.18015\tvalid_1's rmse: 1.60369\n",
      "[300]\ttraining's rmse: 1.054\tvalid_1's rmse: 1.58481\n",
      "[400]\ttraining's rmse: 0.955451\tvalid_1's rmse: 1.5731\n",
      "Early stopping, best iteration is:\n",
      "[456]\ttraining's rmse: 0.911018\tvalid_1's rmse: 1.5679\n",
      "Training until validation scores don't improve for 17 rounds\n",
      "[100]\ttraining's rmse: 1.36219\tvalid_1's rmse: 1.64734\n",
      "[200]\ttraining's rmse: 1.17561\tvalid_1's rmse: 1.6237\n",
      "Early stopping, best iteration is:\n",
      "[225]\ttraining's rmse: 1.13631\tvalid_1's rmse: 1.61367\n",
      "Training until validation scores don't improve for 17 rounds\n",
      "[100]\ttraining's rmse: 1.36464\tvalid_1's rmse: 1.61653\n",
      "Early stopping, best iteration is:\n",
      "[149]\ttraining's rmse: 1.26357\tvalid_1's rmse: 1.59999\n",
      "Mean RMSE: 1.5841566980352786\n",
      "1.5841566980352786\n"
     ]
    }
   ],
   "source": [
    "# We start by defining default parameters and setting the objective metric\n",
    "param = {\"verbose\": -100}  # Set verbosity to -100 to suppress detailed output\n",
    "param['metric'] = 'rmse'   # Set the evaluation metric to RMSE (Root Mean Squared Error)\n",
    "\n",
    "# Lists to save metrics and predictions from the cross-validation folds\n",
    "def cv_train_lgbm(X_train, y_train, params, num_rounds, category):\n",
    "    \"\"\"\n",
    "    Function to perform 14-fold cross-validation and train an LGBM model\n",
    "    Returns the out-of-fold validation score and the models from the cross-validation\n",
    "    Parameters:\n",
    "    X_train (DataFrame): The feature matrix for training.\n",
    "    y_train (Series): The target labels for training.\n",
    "    params (dict): The parameters for training the LightGBM model.\n",
    "    num_rounds (int): The number of boosting iterations (rounds) to train the model.\n",
    "    cat_list (list): A list of categorical feature names or indices.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: A tuple containing the mean RMSE (float) and the list of trained models (list).\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=14, random_state=48, shuffle=True)  # 14-fold cross-validation\n",
    "    lgbm_rmses = []  # List to store RMSE values for each fold\n",
    "    lgbm_y_vals = []  # List to store true values for each fold (not used in this example)\n",
    "    lgbm_y_hats = []  # List to store predicted values for each fold (not used in this example)\n",
    "    lgbm_models = []  # List to store trained models for each fold\n",
    "\n",
    "    # Loop through each fold of the cross-validation\n",
    "    for trn_idx, test_idx in kf.split(X_train, y_train):  # Split the data into training and validation sets\n",
    "        X_tr, X_val = X_train.iloc[trn_idx], X_train.iloc[test_idx]  # Training and validation features\n",
    "        y_tr, y_val = y_train.iloc[trn_idx], y_train.iloc[test_idx]  # Training and validation labels\n",
    "        \n",
    "        # Train the LGBM model using the training data and validation data\n",
    "        lgbm_cls = lgbm_trainer(X_tr, y_tr, X_val, y_val, params, num_rounds, category)\n",
    "        lgbm_models.append(lgbm_cls)  # Save the trained model\n",
    "        \n",
    "        # Use the trained model to make predictions on the validation set\n",
    "        lgbm_y_hat = lgbm_cls.predict(X_val, num_iteration=lgbm_cls.best_iteration)\n",
    "        \n",
    "        # Calculate RMSE (Root Mean Squared Error) between true and predicted values\n",
    "        lgbm_rmse = mean_squared_error(y_val, lgbm_y_hat, squared=False)  # RMSE is the square root of MSE\n",
    "        lgbm_rmses.append(lgbm_rmse)  # Save the RMSE for this fold\n",
    "    \n",
    "    # Calculate the mean RMSE across all folds\n",
    "    lgbm_mean_rmse = statistics.mean(lgbm_rmses)\n",
    "    print(\"Mean RMSE: {}\".format(lgbm_mean_rmse))  # Print the average RMSE across all folds\n",
    "    \n",
    "    return lgbm_mean_rmse, lgbm_models  # Return the average RMSE and the list of trained models\n",
    "\n",
    "\n",
    "# Run the cross-validation function with the training data, parameters, and category list\n",
    "lgbm_rmse, lgbm_models = cv_train_lgbm(X_train, y_train, param, 1000, cat_list)\n",
    "\n",
    "# Print the final average RMSE\n",
    "print(lgbm_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T16:05:57.545772Z",
     "iopub.status.busy": "2024-11-25T16:05:57.545301Z",
     "iopub.status.idle": "2024-11-25T16:05:57.550447Z",
     "shell.execute_reply": "2024-11-25T16:05:57.549473Z",
     "shell.execute_reply.started": "2024-11-25T16:05:57.545719Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Mean RMSE: 1.5841566980352786"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T16:05:57.552973Z",
     "iopub.status.busy": "2024-11-25T16:05:57.552038Z",
     "iopub.status.idle": "2024-11-25T16:05:57.559760Z",
     "shell.execute_reply": "2024-11-25T16:05:57.558917Z",
     "shell.execute_reply.started": "2024-11-25T16:05:57.552885Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T16:05:57.561623Z",
     "iopub.status.busy": "2024-11-25T16:05:57.561182Z",
     "iopub.status.idle": "2024-11-25T16:05:57.570103Z",
     "shell.execute_reply": "2024-11-25T16:05:57.569245Z",
     "shell.execute_reply.started": "2024-11-25T16:05:57.561587Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def catboost_trainer(X_train, y_train, X_val, y_val, num_rounds, categorical):\n",
    "    \"\"\"\n",
    "    Trains a CatBoost regressor model using the training data and evaluates it on the validation data.\n",
    "    Returns the trained CatBoost model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a CatBoost regressor model with specified parameters\n",
    "    # 'iterations' defines the number of boosting iterations (rounds) for training\n",
    "    # 'cat_features' specifies the columns that are categorical\n",
    "    # 'loss_function' is set to 'RMSE' (Root Mean Squared Error) for regression tasks\n",
    "    # 'random_state' ensures reproducibility of results by fixing the random seed\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=num_rounds,  # Number of boosting iterations (rounds)\n",
    "        cat_features=categorical,  # Indices or names of categorical features\n",
    "        loss_function='RMSE',  # Loss function to optimize (Root Mean Squared Error)\n",
    "        random_state=48  # Random state for reproducibility\n",
    "    )\n",
    "    \n",
    "    # Create Pool objects for CatBoost (optimized data format for CatBoost models)\n",
    "    # 'Pool' is used to prepare the training and validation data for CatBoost\n",
    "    train_pool = Pool(X_train, y_train, cat_features=categorical)\n",
    "    validation_pool = Pool(X_val, y_val, cat_features=categorical)\n",
    "\n",
    "    # Train the CatBoost model\n",
    "    # The model will be trained on the 'train_pool' and evaluated on 'validation_pool'\n",
    "    # 'early_stopping_rounds' stops training if the validation performance does not improve for 17 rounds\n",
    "    # 'verbose' logs progress every 100 iterations\n",
    "    model.fit(\n",
    "        train_pool,  # Training data\n",
    "        eval_set=validation_pool,  # Validation data\n",
    "        early_stopping_rounds=17,  # Stop if the validation score doesn't improve for 17 rounds\n",
    "        verbose=100  # Log training progress every 100 iterations\n",
    "    )\n",
    "\n",
    "    # Return the trained model after training is complete\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T16:05:57.572654Z",
     "iopub.status.busy": "2024-11-25T16:05:57.571601Z",
     "iopub.status.idle": "2024-11-25T16:12:04.080250Z",
     "shell.execute_reply": "2024-11-25T16:12:04.079137Z",
     "shell.execute_reply.started": "2024-11-25T16:05:57.572597Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.083028\n",
      "0:\tlearn: 4.4527965\ttest: 4.3296759\tbest: 4.3296759 (0)\ttotal: 96.1ms\tremaining: 1m 36s\n",
      "100:\tlearn: 1.7615857\ttest: 1.7706251\tbest: 1.7706251 (100)\ttotal: 3.37s\tremaining: 30s\n",
      "200:\tlearn: 1.6128713\ttest: 1.6657918\tbest: 1.6657918 (200)\ttotal: 6.68s\tremaining: 26.5s\n",
      "300:\tlearn: 1.5223220\ttest: 1.6145569\tbest: 1.6145428 (299)\ttotal: 9.93s\tremaining: 23.1s\n",
      "400:\tlearn: 1.4500745\ttest: 1.5816070\tbest: 1.5815207 (399)\ttotal: 13.2s\tremaining: 19.7s\n",
      "500:\tlearn: 1.3935976\ttest: 1.5569435\tbest: 1.5569435 (500)\ttotal: 16.5s\tremaining: 16.5s\n",
      "600:\tlearn: 1.3442354\ttest: 1.5385640\tbest: 1.5381388 (598)\ttotal: 19.8s\tremaining: 13.2s\n",
      "700:\tlearn: 1.3020417\ttest: 1.5231324\tbest: 1.5231324 (700)\ttotal: 23.1s\tremaining: 9.84s\n",
      "800:\tlearn: 1.2642206\ttest: 1.5160315\tbest: 1.5160315 (800)\ttotal: 26.4s\tremaining: 6.56s\n",
      "Stopped by overfitting detector  (17 iterations wait)\n",
      "\n",
      "bestTest = 1.514562392\n",
      "bestIteration = 806\n",
      "\n",
      "Shrink model to first 807 iterations.\n",
      "Learning rate set to 0.083028\n",
      "0:\tlearn: 4.4503091\ttest: 4.4452777\tbest: 4.4452777 (0)\ttotal: 71.6ms\tremaining: 1m 11s\n",
      "100:\tlearn: 1.7740797\ttest: 1.7721424\tbest: 1.7721424 (100)\ttotal: 4.06s\tremaining: 36.2s\n",
      "200:\tlearn: 1.6216438\ttest: 1.6683254\tbest: 1.6683254 (200)\ttotal: 7.32s\tremaining: 29.1s\n",
      "300:\tlearn: 1.5264244\ttest: 1.6131443\tbest: 1.6131443 (300)\ttotal: 10.6s\tremaining: 24.7s\n",
      "400:\tlearn: 1.4551720\ttest: 1.5802937\tbest: 1.5802937 (400)\ttotal: 13.9s\tremaining: 20.8s\n",
      "500:\tlearn: 1.3957619\ttest: 1.5547494\tbest: 1.5547494 (500)\ttotal: 17.2s\tremaining: 17.1s\n",
      "600:\tlearn: 1.3457348\ttest: 1.5445523\tbest: 1.5442260 (599)\ttotal: 20.5s\tremaining: 13.6s\n",
      "700:\tlearn: 1.3022651\ttest: 1.5313782\tbest: 1.5313782 (700)\ttotal: 23.8s\tremaining: 10.1s\n",
      "800:\tlearn: 1.2610800\ttest: 1.5162485\tbest: 1.5162485 (800)\ttotal: 27.1s\tremaining: 6.73s\n",
      "900:\tlearn: 1.2265619\ttest: 1.5090653\tbest: 1.5088540 (887)\ttotal: 30.4s\tremaining: 3.34s\n",
      "999:\tlearn: 1.1934830\ttest: 1.5003633\tbest: 1.5003633 (999)\ttotal: 34s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.500363256\n",
      "bestIteration = 999\n",
      "\n",
      "Learning rate set to 0.083028\n",
      "0:\tlearn: 4.4497245\ttest: 4.4667890\tbest: 4.4667890 (0)\ttotal: 57.9ms\tremaining: 57.9s\n",
      "100:\tlearn: 1.7614769\ttest: 1.8108640\tbest: 1.8108640 (100)\ttotal: 3.68s\tremaining: 32.7s\n",
      "200:\tlearn: 1.6073158\ttest: 1.7216883\tbest: 1.7216883 (200)\ttotal: 7s\tremaining: 27.8s\n",
      "300:\tlearn: 1.5136034\ttest: 1.6800644\tbest: 1.6800644 (300)\ttotal: 10.3s\tremaining: 23.8s\n",
      "400:\tlearn: 1.4406225\ttest: 1.6526054\tbest: 1.6526054 (400)\ttotal: 13.6s\tremaining: 20.3s\n",
      "500:\tlearn: 1.3837378\ttest: 1.6339695\tbest: 1.6339661 (498)\ttotal: 16.9s\tremaining: 16.8s\n",
      "600:\tlearn: 1.3327851\ttest: 1.6198593\tbest: 1.6198593 (600)\ttotal: 20.2s\tremaining: 13.4s\n",
      "700:\tlearn: 1.2913989\ttest: 1.6061612\tbest: 1.6061612 (700)\ttotal: 23.6s\tremaining: 10.1s\n",
      "800:\tlearn: 1.2518654\ttest: 1.5969047\tbest: 1.5967568 (788)\ttotal: 27s\tremaining: 6.7s\n",
      "Stopped by overfitting detector  (17 iterations wait)\n",
      "\n",
      "bestTest = 1.596756786\n",
      "bestIteration = 788\n",
      "\n",
      "Shrink model to first 789 iterations.\n",
      "Learning rate set to 0.083028\n",
      "0:\tlearn: 4.4534956\ttest: 4.4040770\tbest: 4.4040770 (0)\ttotal: 44ms\tremaining: 43.9s\n",
      "100:\tlearn: 1.7684328\ttest: 1.7585328\tbest: 1.7585328 (100)\ttotal: 3.33s\tremaining: 29.6s\n",
      "200:\tlearn: 1.6138831\ttest: 1.6635750\tbest: 1.6630232 (198)\ttotal: 7.46s\tremaining: 29.7s\n",
      "300:\tlearn: 1.5190900\ttest: 1.6273643\tbest: 1.6273643 (300)\ttotal: 10.7s\tremaining: 24.9s\n",
      "400:\tlearn: 1.4499967\ttest: 1.6068045\tbest: 1.6067716 (399)\ttotal: 14s\tremaining: 20.9s\n",
      "500:\tlearn: 1.3917699\ttest: 1.5851826\tbest: 1.5851826 (500)\ttotal: 17.3s\tremaining: 17.3s\n",
      "600:\tlearn: 1.3425305\ttest: 1.5764147\tbest: 1.5764147 (600)\ttotal: 20.6s\tremaining: 13.7s\n",
      "700:\tlearn: 1.2982828\ttest: 1.5676324\tbest: 1.5664161 (688)\ttotal: 23.9s\tremaining: 10.2s\n",
      "Stopped by overfitting detector  (17 iterations wait)\n",
      "\n",
      "bestTest = 1.566416092\n",
      "bestIteration = 688\n",
      "\n",
      "Shrink model to first 689 iterations.\n",
      "Learning rate set to 0.083028\n",
      "0:\tlearn: 4.4513099\ttest: 4.4227010\tbest: 4.4227010 (0)\ttotal: 43.9ms\tremaining: 43.9s\n",
      "100:\tlearn: 1.7658643\ttest: 1.7678137\tbest: 1.7678137 (100)\ttotal: 3.36s\tremaining: 29.9s\n",
      "200:\tlearn: 1.6173746\ttest: 1.6642611\tbest: 1.6642611 (200)\ttotal: 6.61s\tremaining: 26.3s\n",
      "300:\tlearn: 1.5177375\ttest: 1.6149540\tbest: 1.6149540 (300)\ttotal: 9.87s\tremaining: 22.9s\n",
      "400:\tlearn: 1.4466663\ttest: 1.5848431\tbest: 1.5848431 (400)\ttotal: 13.2s\tremaining: 19.7s\n",
      "500:\tlearn: 1.3916390\ttest: 1.5698381\tbest: 1.5698381 (500)\ttotal: 17.2s\tremaining: 17.2s\n",
      "600:\tlearn: 1.3402510\ttest: 1.5570925\tbest: 1.5567680 (599)\ttotal: 20.5s\tremaining: 13.6s\n",
      "Stopped by overfitting detector  (17 iterations wait)\n",
      "\n",
      "bestTest = 1.549256465\n",
      "bestIteration = 659\n",
      "\n",
      "Shrink model to first 660 iterations.\n",
      "Learning rate set to 0.083028\n",
      "0:\tlearn: 4.4509199\ttest: 4.4444065\tbest: 4.4444065 (0)\ttotal: 43.5ms\tremaining: 43.5s\n",
      "100:\tlearn: 1.7717652\ttest: 1.7973329\tbest: 1.7973329 (100)\ttotal: 3.33s\tremaining: 29.6s\n",
      "200:\tlearn: 1.6201358\ttest: 1.6948070\tbest: 1.6948070 (200)\ttotal: 6.58s\tremaining: 26.1s\n",
      "300:\tlearn: 1.5242549\ttest: 1.6474956\tbest: 1.6474956 (300)\ttotal: 9.87s\tremaining: 22.9s\n",
      "400:\tlearn: 1.4504654\ttest: 1.6229548\tbest: 1.6229548 (400)\ttotal: 13.1s\tremaining: 19.6s\n",
      "500:\tlearn: 1.3940477\ttest: 1.6119611\tbest: 1.6119611 (500)\ttotal: 16.4s\tremaining: 16.3s\n",
      "600:\tlearn: 1.3417696\ttest: 1.5946909\tbest: 1.5946909 (600)\ttotal: 19.7s\tremaining: 13.1s\n",
      "Stopped by overfitting detector  (17 iterations wait)\n",
      "\n",
      "bestTest = 1.594214859\n",
      "bestIteration = 610\n",
      "\n",
      "Shrink model to first 611 iterations.\n",
      "Learning rate set to 0.083028\n",
      "0:\tlearn: 4.4453743\ttest: 4.5237955\tbest: 4.5237955 (0)\ttotal: 44ms\tremaining: 44s\n",
      "100:\tlearn: 1.7593549\ttest: 1.7830492\tbest: 1.7830492 (100)\ttotal: 3.73s\tremaining: 33.2s\n",
      "200:\tlearn: 1.6178292\ttest: 1.6848623\tbest: 1.6848623 (200)\ttotal: 7.33s\tremaining: 29.1s\n",
      "300:\tlearn: 1.5270087\ttest: 1.6422285\tbest: 1.6422285 (300)\ttotal: 10.7s\tremaining: 24.8s\n",
      "400:\tlearn: 1.4565068\ttest: 1.6140387\tbest: 1.6140387 (400)\ttotal: 14s\tremaining: 20.8s\n",
      "500:\tlearn: 1.3957042\ttest: 1.5885729\tbest: 1.5885729 (500)\ttotal: 17.3s\tremaining: 17.2s\n",
      "600:\tlearn: 1.3446276\ttest: 1.5707711\tbest: 1.5707666 (599)\ttotal: 20.6s\tremaining: 13.7s\n",
      "Stopped by overfitting detector  (17 iterations wait)\n",
      "\n",
      "bestTest = 1.559960294\n",
      "bestIteration = 665\n",
      "\n",
      "Shrink model to first 666 iterations.\n",
      "Learning rate set to 0.083028\n",
      "0:\tlearn: 4.4541764\ttest: 4.3800349\tbest: 4.3800349 (0)\ttotal: 45.4ms\tremaining: 45.3s\n",
      "100:\tlearn: 1.7743824\ttest: 1.7068032\tbest: 1.7068032 (100)\ttotal: 3.33s\tremaining: 29.7s\n",
      "200:\tlearn: 1.6159591\ttest: 1.6138455\tbest: 1.6138455 (200)\ttotal: 6.71s\tremaining: 26.7s\n",
      "300:\tlearn: 1.5269706\ttest: 1.5724691\tbest: 1.5724691 (300)\ttotal: 9.95s\tremaining: 23.1s\n",
      "400:\tlearn: 1.4574550\ttest: 1.5441029\tbest: 1.5441029 (400)\ttotal: 13.8s\tremaining: 20.6s\n",
      "500:\tlearn: 1.4065656\ttest: 1.5225922\tbest: 1.5225922 (500)\ttotal: 17.3s\tremaining: 17.2s\n",
      "600:\tlearn: 1.3568563\ttest: 1.5050116\tbest: 1.5050116 (600)\ttotal: 20.6s\tremaining: 13.7s\n",
      "700:\tlearn: 1.3148005\ttest: 1.4896293\tbest: 1.4896293 (700)\ttotal: 23.9s\tremaining: 10.2s\n",
      "800:\tlearn: 1.2723343\ttest: 1.4782755\tbest: 1.4782164 (799)\ttotal: 27.2s\tremaining: 6.77s\n",
      "Stopped by overfitting detector  (17 iterations wait)\n",
      "\n",
      "bestTest = 1.470908804\n",
      "bestIteration = 862\n",
      "\n",
      "Shrink model to first 863 iterations.\n",
      "Learning rate set to 0.083028\n",
      "0:\tlearn: 4.4435119\ttest: 4.4589938\tbest: 4.4589938 (0)\ttotal: 43.3ms\tremaining: 43.3s\n",
      "100:\tlearn: 1.7541967\ttest: 1.9628610\tbest: 1.9628610 (100)\ttotal: 3.32s\tremaining: 29.5s\n",
      "200:\tlearn: 1.6050913\ttest: 1.8828053\tbest: 1.8817111 (199)\ttotal: 6.64s\tremaining: 26.4s\n",
      "300:\tlearn: 1.5144252\ttest: 1.8382882\tbest: 1.8382882 (300)\ttotal: 9.88s\tremaining: 22.9s\n",
      "400:\tlearn: 1.4444497\ttest: 1.8119153\tbest: 1.8117168 (395)\ttotal: 13.2s\tremaining: 19.7s\n",
      "500:\tlearn: 1.3889209\ttest: 1.7956275\tbest: 1.7951671 (499)\ttotal: 17s\tremaining: 16.9s\n",
      "600:\tlearn: 1.3361482\ttest: 1.7814578\tbest: 1.7814578 (600)\ttotal: 20.5s\tremaining: 13.6s\n",
      "700:\tlearn: 1.2950498\ttest: 1.7704267\tbest: 1.7704267 (700)\ttotal: 23.8s\tremaining: 10.1s\n",
      "800:\tlearn: 1.2560864\ttest: 1.7619152\tbest: 1.7619152 (800)\ttotal: 27.1s\tremaining: 6.73s\n",
      "900:\tlearn: 1.2212577\ttest: 1.7531176\tbest: 1.7531176 (900)\ttotal: 30.4s\tremaining: 3.34s\n",
      "999:\tlearn: 1.1903554\ttest: 1.7463228\tbest: 1.7460117 (998)\ttotal: 33.7s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.746011732\n",
      "bestIteration = 998\n",
      "\n",
      "Shrink model to first 999 iterations.\n",
      "Learning rate set to 0.083028\n",
      "0:\tlearn: 4.4554711\ttest: 4.3730681\tbest: 4.3730681 (0)\ttotal: 43.4ms\tremaining: 43.4s\n",
      "100:\tlearn: 1.7613454\ttest: 1.8127025\tbest: 1.8127025 (100)\ttotal: 3.38s\tremaining: 30.1s\n",
      "200:\tlearn: 1.6114643\ttest: 1.7252848\tbest: 1.7252848 (200)\ttotal: 6.67s\tremaining: 26.5s\n",
      "300:\tlearn: 1.5200805\ttest: 1.6847970\tbest: 1.6847970 (300)\ttotal: 10s\tremaining: 23.2s\n",
      "400:\tlearn: 1.4476074\ttest: 1.6574845\tbest: 1.6574845 (400)\ttotal: 13.3s\tremaining: 19.9s\n",
      "500:\tlearn: 1.3900980\ttest: 1.6439677\tbest: 1.6436810 (499)\ttotal: 17.3s\tremaining: 17.3s\n",
      "600:\tlearn: 1.3380160\ttest: 1.6288982\tbest: 1.6288240 (595)\ttotal: 20.7s\tremaining: 13.8s\n",
      "700:\tlearn: 1.2959102\ttest: 1.6194594\tbest: 1.6194594 (700)\ttotal: 24s\tremaining: 10.2s\n",
      "800:\tlearn: 1.2572193\ttest: 1.6083454\tbest: 1.6083454 (800)\ttotal: 27.3s\tremaining: 6.77s\n",
      "900:\tlearn: 1.2200997\ttest: 1.6007462\tbest: 1.6005766 (899)\ttotal: 30.6s\tremaining: 3.37s\n",
      "999:\tlearn: 1.1844408\ttest: 1.5928398\tbest: 1.5928398 (999)\ttotal: 33.9s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.592839848\n",
      "bestIteration = 999\n",
      "\n",
      "Learning rate set to 0.083029\n",
      "0:\tlearn: 4.4410688\ttest: 4.5629542\tbest: 4.5629542 (0)\ttotal: 42.5ms\tremaining: 42.5s\n",
      "100:\tlearn: 1.7379307\ttest: 2.0238363\tbest: 2.0238363 (100)\ttotal: 3.32s\tremaining: 29.5s\n",
      "200:\tlearn: 1.5923426\ttest: 1.9284218\tbest: 1.9284218 (200)\ttotal: 6.65s\tremaining: 26.4s\n",
      "300:\tlearn: 1.4990811\ttest: 1.8863970\tbest: 1.8863970 (300)\ttotal: 9.89s\tremaining: 23s\n",
      "400:\tlearn: 1.4309695\ttest: 1.8669176\tbest: 1.8669176 (400)\ttotal: 13.2s\tremaining: 19.7s\n",
      "500:\tlearn: 1.3718734\ttest: 1.8515131\tbest: 1.8515131 (500)\ttotal: 17.3s\tremaining: 17.2s\n",
      "Stopped by overfitting detector  (17 iterations wait)\n",
      "\n",
      "bestTest = 1.839766805\n",
      "bestIteration = 561\n",
      "\n",
      "Shrink model to first 562 iterations.\n",
      "Learning rate set to 0.083029\n",
      "0:\tlearn: 4.4421538\ttest: 4.5708768\tbest: 4.5708768 (0)\ttotal: 43.5ms\tremaining: 43.4s\n",
      "100:\tlearn: 1.7621976\ttest: 1.8121119\tbest: 1.8121119 (100)\ttotal: 3.33s\tremaining: 29.6s\n",
      "200:\tlearn: 1.6112671\ttest: 1.7154434\tbest: 1.7154434 (200)\ttotal: 6.67s\tremaining: 26.5s\n",
      "300:\tlearn: 1.5162641\ttest: 1.6674608\tbest: 1.6674608 (300)\ttotal: 9.96s\tremaining: 23.1s\n",
      "400:\tlearn: 1.4463134\ttest: 1.6424283\tbest: 1.6423901 (394)\ttotal: 13.3s\tremaining: 19.9s\n",
      "500:\tlearn: 1.3905188\ttest: 1.6230927\tbest: 1.6229629 (499)\ttotal: 16.6s\tremaining: 16.6s\n",
      "600:\tlearn: 1.3421026\ttest: 1.6095597\tbest: 1.6095332 (598)\ttotal: 19.9s\tremaining: 13.2s\n",
      "700:\tlearn: 1.2970849\ttest: 1.5982376\tbest: 1.5982287 (699)\ttotal: 23.2s\tremaining: 9.88s\n",
      "Stopped by overfitting detector  (17 iterations wait)\n",
      "\n",
      "bestTest = 1.59298152\n",
      "bestIteration = 733\n",
      "\n",
      "Shrink model to first 734 iterations.\n",
      "Learning rate set to 0.083029\n",
      "0:\tlearn: 4.4472494\ttest: 4.5281925\tbest: 4.5281925 (0)\ttotal: 47.7ms\tremaining: 47.6s\n",
      "100:\tlearn: 1.7639289\ttest: 1.8346686\tbest: 1.8346686 (100)\ttotal: 4.15s\tremaining: 36.9s\n",
      "200:\tlearn: 1.6047226\ttest: 1.7346237\tbest: 1.7346237 (200)\ttotal: 7.46s\tremaining: 29.7s\n",
      "300:\tlearn: 1.5065687\ttest: 1.6943485\tbest: 1.6943485 (300)\ttotal: 10.8s\tremaining: 25s\n",
      "400:\tlearn: 1.4373546\ttest: 1.6741619\tbest: 1.6741344 (398)\ttotal: 14.1s\tremaining: 21.1s\n",
      "500:\tlearn: 1.3818866\ttest: 1.6601445\tbest: 1.6600386 (496)\ttotal: 17.4s\tremaining: 17.3s\n",
      "600:\tlearn: 1.3338291\ttest: 1.6463524\tbest: 1.6460978 (598)\ttotal: 20.8s\tremaining: 13.8s\n",
      "700:\tlearn: 1.2904472\ttest: 1.6358004\tbest: 1.6343219 (692)\ttotal: 24s\tremaining: 10.3s\n",
      "Stopped by overfitting detector  (17 iterations wait)\n",
      "\n",
      "bestTest = 1.634321857\n",
      "bestIteration = 692\n",
      "\n",
      "Shrink model to first 693 iterations.\n",
      "Learning rate set to 0.083029\n",
      "0:\tlearn: 4.4563427\ttest: 4.3844661\tbest: 4.3844661 (0)\ttotal: 44.2ms\tremaining: 44.2s\n",
      "100:\tlearn: 1.7707080\ttest: 1.7588163\tbest: 1.7588163 (100)\ttotal: 3.38s\tremaining: 30.1s\n",
      "200:\tlearn: 1.6151254\ttest: 1.6845646\tbest: 1.6845646 (200)\ttotal: 6.74s\tremaining: 26.8s\n",
      "300:\tlearn: 1.5171905\ttest: 1.6506244\tbest: 1.6506244 (300)\ttotal: 10.2s\tremaining: 23.6s\n",
      "400:\tlearn: 1.4423728\ttest: 1.6294539\tbest: 1.6292992 (397)\ttotal: 14.1s\tremaining: 21.1s\n",
      "Stopped by overfitting detector  (17 iterations wait)\n",
      "\n",
      "bestTest = 1.626828832\n",
      "bestIteration = 427\n",
      "\n",
      "Shrink model to first 428 iterations.\n",
      "Mean RMSE: 1.5989421099589922\n",
      "1.5989421099589922\n"
     ]
    }
   ],
   "source": [
    "# We start with default parameters and just define the objective metric\n",
    "param = {\"verbose\": -100}  # Silence the verbose output for training logs\n",
    "param['metric'] = 'rmse'  # Set the metric for evaluation to RMSE (Root Mean Squared Error)\n",
    "\n",
    "# Lists to save metrics and predictions from each fold\n",
    "def cv_train_cat(X_train, y_train, params, num_rounds, cat_list):\n",
    "    \"\"\"\n",
    "    Function to perform 5-fold cross-validation using the CatBoost model\n",
    "    and return the out-of-fold validation score (mean RMSE) and models.\n",
    "    \n",
    "    Parameters:\n",
    "    X_train (DataFrame): The feature matrix for training.\n",
    "    y_train (Series): The target labels for training.\n",
    "    params (dict): The parameters for training the CatBoost model.\n",
    "    num_rounds (int): The number of boosting iterations (rounds) to train the model.\n",
    "    cat_list (list): A list of categorical feature names or indices.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: A tuple containing the mean RMSE (float) and the list of trained models (list).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create KFold cross-validator (14 splits in this case, shuffle the data, and set random state for reproducibility)\n",
    "    kf = KFold(n_splits=14, random_state=48, shuffle=True)  # Split data into 14 folds\n",
    "    \n",
    "    cat_rmses = []  # List to save the RMSE for each fold\n",
    "    cat_y_vals = []  # List to store actual target values for each fold (for evaluation purposes)\n",
    "    cat_y_hats = []  # List to store predicted values for each fold\n",
    "    cat_models = []  # List to store the trained models from each fold\n",
    "\n",
    "    # Loop over the splits (train-test splits generated by KFold)\n",
    "    for trn_idx, test_idx in kf.split(X_train, y_train):\n",
    "        # Create training and validation sets based on the current fold split\n",
    "        X_tr, X_val = X_train.iloc[trn_idx], X_train.iloc[test_idx]\n",
    "        y_tr, y_val = y_train.iloc[trn_idx], y_train.iloc[test_idx]\n",
    "        \n",
    "        # Train the model on the training set and validate on the validation set\n",
    "        cat_cls = catboost_trainer(X_tr, y_tr, X_val, y_val, num_rounds, cat_list)\n",
    "        cat_models.append(cat_cls)  # Save the trained model from this fold\n",
    "        \n",
    "        # Predict using the trained model (using the validation set for predictions)\n",
    "        cat_y_hat = cat_cls.predict(X_val)\n",
    "        \n",
    "        # Calculate the RMSE for this fold (Root Mean Squared Error)\n",
    "        cat_rmse = mean_squared_error(y_val, cat_y_hat, squared=False)  # squared=False returns RMSE instead of MSE\n",
    "        cat_rmses.append(cat_rmse)  # Store the RMSE for this fold\n",
    "    \n",
    "    # Calculate the mean RMSE across all folds\n",
    "    cat_mean_rmse = statistics.mean(cat_rmses)\n",
    "    print(\"Mean RMSE: {}\".format(cat_mean_rmse))  # Print the mean RMSE for the cross-validation\n",
    "    return cat_mean_rmse, cat_models  # Return the mean RMSE and list of models\n",
    "\n",
    "# X_train, y_train, and cat_list are already defined\n",
    "cat_rmse, cat_models = cv_train_cat(X_train, y_train, param, 1000, cat_list)\n",
    "print(cat_rmse)  # Print the final mean RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T16:12:04.082375Z",
     "iopub.status.busy": "2024-11-25T16:12:04.081880Z",
     "iopub.status.idle": "2024-11-25T16:12:04.088227Z",
     "shell.execute_reply": "2024-11-25T16:12:04.086871Z",
     "shell.execute_reply.started": "2024-11-25T16:12:04.082323Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Mean RMSE: 1.5989421099589922"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ensemble model and Predict on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T16:12:04.090169Z",
     "iopub.status.busy": "2024-11-25T16:12:04.089819Z",
     "iopub.status.idle": "2024-11-25T16:12:06.707929Z",
     "shell.execute_reply": "2024-11-25T16:12:06.706974Z",
     "shell.execute_reply.started": "2024-11-25T16:12:04.090139Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set the data path for test data\n",
    "DATA_PATH = '/kaggle/input/yango-accra-mobility-dataset'\n",
    "test = pd.read_csv(os.path.join(DATA_PATH, 'Test.csv'))\n",
    "test_df = test.copy()\n",
    "\n",
    "# Preprocess the dataset to match train set (custom functions assumed to exist)\n",
    "test_df = look_up_from_graph(test_df, graph_df, preliminary_columns)\n",
    "test_df = test_df[X_train.columns.tolist()]\n",
    "test_df, _ = change_object_to_cat(test_df)\n",
    "pred_df = test_df.copy()\n",
    "\n",
    "# --- Prediction on the Test Set ---\n",
    "# Predict using LGBM models\n",
    "for i, model in enumerate(lgbm_models):\n",
    "    if hasattr(model, 'best_iteration') and model.best_iteration:\n",
    "        pred_df[\"pred_lgbm_{}\".format(i)] = model.predict(test_df, num_iteration=model.best_iteration)\n",
    "    else:\n",
    "        pred_df[\"pred_lgbm_{}\".format(i)] = model.predict(test_df)\n",
    "\n",
    "# Predict using CatBoost models\n",
    "for i, model in enumerate(cat_models):\n",
    "    pred_df[\"pred_catboost_{}\".format(i)] = model.predict(test_df)\n",
    "\n",
    "# --- Ensemble the Predictions (Mean and Median) ---\n",
    "# Calculate mean and median of the predictions from the models\n",
    "sub_df = pred_df.copy()\n",
    "lgbm_preds = pred_df.filter(like='pred_lgbm').values\n",
    "catboost_preds = pred_df.filter(like='pred_catboost').values\n",
    "\n",
    "# Combine LGBM and CatBoost predictions\n",
    "combined_preds = pd.concat([pd.DataFrame(lgbm_preds), pd.DataFrame(catboost_preds)], axis=1)\n",
    "\n",
    "# Calculate the mean and median\n",
    "sub_df[\"mean_pred\"] = combined_preds.mean(axis=1)\n",
    "sub_df[\"median_pred\"] = combined_preds.median(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T16:12:06.711312Z",
     "iopub.status.busy": "2024-11-25T16:12:06.711002Z",
     "iopub.status.idle": "2024-11-25T16:12:06.759573Z",
     "shell.execute_reply": "2024-11-25T16:12:06.758564Z",
     "shell.execute_reply.started": "2024-11-25T16:12:06.711286Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12170463379909937152_X_last_weekday_X_morning_...</td>\n",
       "      <td>14.294417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12462211467129128960_X_lbo_weekday_X_evening_r...</td>\n",
       "      <td>8.897416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17199689856168204288_X_last_weekday_X_evening_...</td>\n",
       "      <td>16.013050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12559239482074976256_X_second_weekday_X_evenin...</td>\n",
       "      <td>12.293271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3456135199470793216_X_other_holiday_X_evening_...</td>\n",
       "      <td>13.436907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ID     target\n",
       "0  12170463379909937152_X_last_weekday_X_morning_...  14.294417\n",
       "1  12462211467129128960_X_lbo_weekday_X_evening_r...   8.897416\n",
       "2  17199689856168204288_X_last_weekday_X_evening_...  16.013050\n",
       "3  12559239482074976256_X_second_weekday_X_evenin...  12.293271\n",
       "4  3456135199470793216_X_other_holiday_X_evening_...  13.436907"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Create a Submission File ---\n",
    "sub_file = pd.DataFrame({'ID': test.ID, 'target': sub_df.mean_pred})  # Choose mean or median here\n",
    "sub_file.to_csv('lgbm_catboost_ensemble_mean_submission14.csv', index=False)\n",
    "sub_file.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank You!"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6148331,
     "sourceId": 9990281,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
